#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LoFTRæ·±åº¦å­¦ä¹ å¯¹é½è¯Šæ–­å·¥å…·

ä¸“é—¨ç”¨äºè°ƒè¯•å’Œåˆ†æLoFTRæ·±åº¦å­¦ä¹ å›¾åƒå¯¹é½çš„æ•ˆæœ
"""

import cv2
import numpy as np
import torch
import kornia.feature as KF
from pathlib import Path
import matplotlib.pyplot as plt
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LoFTRDebugger:
    """LoFTRè¯Šæ–­å·¥å…·"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆå§‹åŒ–LoFTR
        self.init_loftr()
    
    def init_loftr(self):
        """åˆå§‹åŒ–LoFTRæ¨¡å‹"""
        try:
            local_loftr_path = "/mnt/houjinliang/MyDevProject/TickTock-NPUEveryday/Align/loftr_outdoor.ckpt"
            
            if Path(local_loftr_path).exists():
                # åŠ è½½æœ¬åœ°æ¨¡å‹
                state_dict = torch.load(local_loftr_path, map_location=self.device)
                self.loftr = KF.LoFTR(pretrained=None)
                self.loftr.load_state_dict(state_dict['state_dict'])
                self.loftr = self.loftr.to(self.device).eval()
                logger.info("âœ… LoFTRæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            else:
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {local_loftr_path}")
                
        except Exception as e:
            logger.error(f"âŒ LoFTRåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def preprocess_image(self, img, target_size=640):
        """é¢„å¤„ç†å›¾åƒ"""
        # è½¬æ¢ä¸ºç°åº¦å›¾åƒ
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img
        
        # è·å–åŸå§‹å°ºå¯¸
        h, w = gray.shape
        
        # è®¡ç®—ç¼©æ”¾å› å­ï¼Œä¿æŒçºµæ¨ªæ¯”
        scale = min(target_size / w, target_size / h)
        new_w, new_h = int(w * scale), int(h * scale)
        
        # è°ƒæ•´å¤§å°
        resized = cv2.resize(gray, (new_w, new_h))
        
        # åˆ›å»ºå¡«å……çš„æ­£æ–¹å½¢å›¾åƒ
        padded = np.zeros((target_size, target_size), dtype=np.uint8)
        start_x = (target_size - new_w) // 2
        start_y = (target_size - new_h) // 2
        padded[start_y:start_y+new_h, start_x:start_x+new_w] = resized
        
        # è½¬æ¢ä¸ºtensor
        tensor_img = torch.from_numpy(padded).float().unsqueeze(0).unsqueeze(0).to(self.device) / 255.0
        
        return tensor_img, scale, (start_x, start_y, new_w, new_h)
    
    def match_images_loftr(self, img1, img2, confidence_thresh=0.2):
        """ä½¿ç”¨LoFTRåŒ¹é…ä¸¤å¼ å›¾åƒ"""
        try:
            # é¢„å¤„ç†å›¾åƒ
            tensor1, scale1, (sx1, sy1, w1, h1) = self.preprocess_image(img1)
            tensor2, scale2, (sx2, sy2, w2, h2) = self.preprocess_image(img2)
            
            logger.info(f"å›¾åƒ1é¢„å¤„ç†: scale={scale1:.3f}, size=({w1}x{h1}), offset=({sx1},{sy1})")
            logger.info(f"å›¾åƒ2é¢„å¤„ç†: scale={scale2:.3f}, size=({w2}x{h2}), offset=({sx2},{sy2})")
            
            with torch.no_grad():
                # å‡†å¤‡è¾“å…¥æ•°æ®
                input_dict = {
                    'image0': tensor1,  # [1, 1, H, W]
                    'image1': tensor2   # [1, 1, H, W]
                }
                
                # è¿è¡ŒLoFTR
                logger.info("ğŸ” è¿è¡ŒLoFTRåŒ¹é…...")
                correspondences = self.loftr(input_dict)
                
                # æå–åŒ¹é…ç»“æœ
                mkpts0 = correspondences['keypoints0'].cpu().numpy()  # [N, 2]
                mkpts1 = correspondences['keypoints1'].cpu().numpy()  # [N, 2]
                mconf = correspondences['confidence'].cpu().numpy()   # [N]
                
                logger.info(f"ğŸ“Š åŸå§‹åŒ¹é…æ•°é‡: {len(mkpts0)}")
                logger.info(f"ğŸ“Š ç½®ä¿¡åº¦èŒƒå›´: {mconf.min():.3f} - {mconf.max():.3f}")
                logger.info(f"ğŸ“Š å¹³å‡ç½®ä¿¡åº¦: {mconf.mean():.3f}")
                
                # ç½®ä¿¡åº¦åˆ†æ
                high_conf = np.sum(mconf > 0.8)
                med_conf = np.sum((mconf > 0.5) & (mconf <= 0.8))
                low_conf = np.sum((mconf > confidence_thresh) & (mconf <= 0.5))
                very_low_conf = np.sum(mconf <= confidence_thresh)
                
                logger.info(f"ğŸ“Š ç½®ä¿¡åº¦åˆ†å¸ƒ:")
                logger.info(f"   é«˜ç½®ä¿¡åº¦(>0.8): {high_conf}")
                logger.info(f"   ä¸­ç½®ä¿¡åº¦(0.5-0.8): {med_conf}")
                logger.info(f"   ä½ç½®ä¿¡åº¦({confidence_thresh}-0.5): {low_conf}")
                logger.info(f"   æä½ç½®ä¿¡åº¦(<{confidence_thresh}): {very_low_conf}")
                
                # è¿‡æ»¤ä½ç½®ä¿¡åº¦åŒ¹é…
                mask = mconf > confidence_thresh
                mkpts0_filtered = mkpts0[mask]
                mkpts1_filtered = mkpts1[mask]
                mconf_filtered = mconf[mask]
                
                logger.info(f"ğŸ“Š è¿‡æ»¤ååŒ¹é…æ•°é‡: {len(mkpts0_filtered)}")
                
                if len(mkpts0_filtered) == 0:
                    logger.warning("âš ï¸  æ²¡æœ‰è¶³å¤Ÿç½®ä¿¡åº¦çš„åŒ¹é…ç‚¹")
                    return [], [], []
                
                # å°†åæ ‡ä»å¡«å……å›¾åƒè½¬æ¢å›åŸå§‹å›¾åƒ
                # å›¾åƒ1çš„åæ ‡è½¬æ¢
                mkpts0_orig = mkpts0_filtered.copy()
                mkpts0_orig[:, 0] = (mkpts0_orig[:, 0] - sx1) / scale1  # xåæ ‡
                mkpts0_orig[:, 1] = (mkpts0_orig[:, 1] - sy1) / scale1  # yåæ ‡
                
                # å›¾åƒ2çš„åæ ‡è½¬æ¢
                mkpts1_orig = mkpts1_filtered.copy()
                mkpts1_orig[:, 0] = (mkpts1_orig[:, 0] - sx2) / scale2  # xåæ ‡
                mkpts1_orig[:, 1] = (mkpts1_orig[:, 1] - sy2) / scale2  # yåæ ‡
                
                # è¿‡æ»¤è¶…å‡ºåŸå§‹å›¾åƒè¾¹ç•Œçš„ç‚¹
                h1_orig, w1_orig = img1.shape[:2]
                h2_orig, w2_orig = img2.shape[:2]
                
                valid_mask = ((mkpts0_orig[:, 0] >= 0) & (mkpts0_orig[:, 0] < w1_orig) &
                            (mkpts0_orig[:, 1] >= 0) & (mkpts0_orig[:, 1] < h1_orig) &
                            (mkpts1_orig[:, 0] >= 0) & (mkpts1_orig[:, 0] < w2_orig) &
                            (mkpts1_orig[:, 1] >= 0) & (mkpts1_orig[:, 1] < h2_orig))
                
                mkpts0_final = mkpts0_orig[valid_mask]
                mkpts1_final = mkpts1_orig[valid_mask]
                mconf_final = mconf_filtered[valid_mask]
                
                logger.info(f"ğŸ“Š æœ‰æ•ˆåŒ¹é…æ•°é‡: {len(mkpts0_final)}")
                
                # åˆ›å»ºOpenCVåŒ¹é…æ ¼å¼
                matches = []
                kp1_list = []
                kp2_list = []
                
                for i in range(len(mkpts0_final)):
                    kp1_list.append(cv2.KeyPoint(x=mkpts0_final[i, 0], y=mkpts0_final[i, 1], size=1))
                    kp2_list.append(cv2.KeyPoint(x=mkpts1_final[i, 0], y=mkpts1_final[i, 1], size=1))
                    matches.append(cv2.DMatch(i, i, float(1.0 - mconf_final[i])))
                
                return matches, kp1_list, kp2_list
                
        except Exception as e:
            logger.error(f"âŒ LoFTRåŒ¹é…å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return [], [], []
    
    def estimate_homography_robust(self, kp1, kp2, matches, ransac_thresh=5.0):
        """é²æ£’çš„å•åº”æ€§çŸ©é˜µä¼°è®¡"""
        if len(matches) < 4:
            logger.warning(f"âš ï¸  åŒ¹é…ç‚¹æ•°é‡ä¸è¶³ ({len(matches)})ï¼Œæ— æ³•è®¡ç®—å•åº”æ€§çŸ©é˜µ")
            return None, 0
        
        # æå–åŒ¹é…ç‚¹åæ ‡
        src_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
        
        logger.info(f"ğŸ” RANSACå‚æ•°: é˜ˆå€¼={ransac_thresh}, æœ€å¤§è¿­ä»£=5000")
        
        # ä½¿ç”¨RANSACä¼°è®¡å•åº”æ€§çŸ©é˜µ
        homography, mask = cv2.findHomography(
            src_pts, dst_pts, 
            cv2.RANSAC, 
            ransacReprojThreshold=ransac_thresh,
            maxIters=5000,
            confidence=0.99
        )
        
        inliers = np.sum(mask) if mask is not None else 0
        outliers = len(matches) - inliers
        
        logger.info(f"ğŸ“Š RANSACç»“æœ: å†…ç‚¹={inliers}, å¤–ç‚¹={outliers}, å†…ç‚¹æ¯”ä¾‹={inliers/len(matches)*100:.1f}%")
        
        if homography is not None:
            # åˆ†æå•åº”æ€§çŸ©é˜µ
            det = np.linalg.det(homography[:2, :2])
            logger.info(f"ğŸ“Š å•åº”æ€§çŸ©é˜µè¡Œåˆ—å¼: {det:.3f}")
            
            # æ£€æŸ¥æ¡ä»¶æ•°
            cond = np.linalg.cond(homography)
            logger.info(f"ğŸ“Š å•åº”æ€§çŸ©é˜µæ¡ä»¶æ•°: {cond:.1f}")
            
            if cond > 1000:
                logger.warning("âš ï¸  å•åº”æ€§çŸ©é˜µæ¡ä»¶æ•°è¿‡é«˜ï¼Œå¯èƒ½ä¸ç¨³å®š")
        
        return homography, inliers
    
    def visualize_matches(self, img1, img2, kp1, kp2, matches, output_path="debug_matches.jpg"):
        """å¯è§†åŒ–åŒ¹é…ç»“æœ"""
        try:
            # åˆ›å»ºåŒ¹é…å¯è§†åŒ–å›¾åƒ
            img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:50], None, 
                                        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
            
            # ä¿å­˜å›¾åƒ
            cv2.imwrite(output_path, img_matches)
            logger.info(f"ğŸ“· åŒ¹é…å¯è§†åŒ–å·²ä¿å­˜: {output_path}")
            
        except Exception as e:
            logger.error(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
    
    def debug_image_pair(self, img1_path, img2_path, output_dir="debug_output"):
        """è°ƒè¯•ä¸€å¯¹å›¾åƒçš„åŒ¹é…æ•ˆæœ"""
        logger.info("=" * 80)
        logger.info(f"ğŸ” è°ƒè¯•å›¾åƒå¯¹: {Path(img1_path).name} vs {Path(img2_path).name}")
        logger.info("=" * 80)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        # è¯»å–å›¾åƒ
        img1 = cv2.imread(str(img1_path))
        img2 = cv2.imread(str(img2_path))
        
        if img1 is None or img2 is None:
            logger.error("âŒ æ— æ³•è¯»å–å›¾åƒ")
            return
        
        logger.info(f"ğŸ“ å›¾åƒ1å°ºå¯¸: {img1.shape}")
        logger.info(f"ğŸ“ å›¾åƒ2å°ºå¯¸: {img2.shape}")
        
        # åˆ†æå›¾åƒç»Ÿè®¡ä¿¡æ¯
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2
        
        logger.info(f"ğŸ“Š å›¾åƒ1ç»Ÿè®¡: å‡å€¼={gray1.mean():.1f}, æ ‡å‡†å·®={gray1.std():.1f}, èŒƒå›´=[{gray1.min()}-{gray1.max()}]")
        logger.info(f"ğŸ“Š å›¾åƒ2ç»Ÿè®¡: å‡å€¼={gray2.mean():.1f}, æ ‡å‡†å·®={gray2.std():.1f}, èŒƒå›´=[{gray2.min()}-{gray2.max()}]")
        
        # æµ‹è¯•ä¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼
        confidence_thresholds = [0.1, 0.2, 0.3, 0.5]
        
        best_matches = 0
        best_threshold = 0.2
        best_result = None
        
        for thresh in confidence_thresholds:
            logger.info(f"\nğŸ” æµ‹è¯•ç½®ä¿¡åº¦é˜ˆå€¼: {thresh}")
            
            matches, kp1, kp2 = self.match_images_loftr(img1, img2, confidence_thresh=thresh)
            
            if len(matches) >= 4:
                homography, inliers = self.estimate_homography_robust(kp1, kp2, matches)
                
                if len(matches) > best_matches:
                    best_matches = len(matches)
                    best_threshold = thresh
                    best_result = (matches, kp1, kp2, homography, inliers)
                
                # ä¿å­˜å¯è§†åŒ–
                vis_path = output_dir / f"matches_thresh_{thresh}.jpg"
                self.visualize_matches(img1, img2, kp1, kp2, matches, str(vis_path))
            else:
                logger.warning(f"âš ï¸  ç½®ä¿¡åº¦{thresh}: åŒ¹é…ç‚¹ä¸è¶³({len(matches)})")
        
        # è¾“å‡ºæœ€ä½³ç»“æœ
        if best_result:
            matches, kp1, kp2, homography, inliers = best_result
            logger.info("\n" + "=" * 50)
            logger.info(f"ğŸ† æœ€ä½³ç»“æœ (é˜ˆå€¼={best_threshold}):")
            logger.info(f"   åŒ¹é…ç‚¹æ•°: {len(matches)}")
            logger.info(f"   å†…ç‚¹æ•°: {inliers}")
            logger.info(f"   æˆåŠŸç‡: {inliers/len(matches)*100:.1f}% ({inliers}/{len(matches)})")
            logger.info(f"   å¯¹é½: {'âœ… æˆåŠŸ' if homography is not None else 'âŒ å¤±è´¥'}")
            
            # ä¿å­˜æœ€ä½³åŒ¹é…å¯è§†åŒ–
            best_vis_path = output_dir / f"best_matches_{Path(img1_path).stem}_vs_{Path(img2_path).stem}.jpg"
            self.visualize_matches(img1, img2, kp1, kp2, matches, str(best_vis_path))
            
            return homography is not None, len(matches), inliers
        else:
            logger.warning("âŒ æ‰€æœ‰é˜ˆå€¼éƒ½æ— æ³•äº§ç”Ÿè¶³å¤Ÿçš„åŒ¹é…ç‚¹")
            return False, 0, 0

def main():
    """ä¸»å‡½æ•°ï¼šè°ƒè¯•NPU-Everyday-Sampleä¸­çš„å›¾åƒ"""
    debugger = LoFTRDebugger()
    
    # è¾“å…¥ç›®å½•
    input_dir = Path("NPU-Everyday-Sample")
    if not input_dir.exists():
        logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    # è·å–å›¾åƒæ–‡ä»¶ - é€’å½’æœç´¢
    image_files = []
    for ext in ['.jpg', '.jpeg', '.png']:
        image_files.extend(list(input_dir.rglob(f"*{ext}")))
        image_files.extend(list(input_dir.rglob(f"*{ext.upper()}")))
    
    image_files.sort()
    logger.info(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
    
    if len(image_files) < 2:
        logger.error("âŒ å›¾åƒæ•°é‡ä¸è¶³")
        return
    
    # é€‰æ‹©å‚è€ƒå›¾åƒ
    ref_img = image_files[0]
    logger.info(f"ğŸ“Œ å‚è€ƒå›¾åƒ: {ref_img.name}")
    
    # è°ƒè¯•å‰å‡ å¯¹å›¾åƒ
    success_count = 0
    total_matches = 0
    total_inliers = 0
    
    max_debug = min(5, len(image_files) - 1)  # è°ƒè¯•å‰5å¯¹
    
    for i in range(1, max_debug + 1):
        curr_img = image_files[i]
        
        success, matches, inliers = debugger.debug_image_pair(ref_img, curr_img)
        
        if success:
            success_count += 1
        total_matches += matches
        total_inliers += inliers
    
    # è¾“å‡ºæ€»ç»“
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š LoFTRè¯Šæ–­æ€»ç»“")
    logger.info("=" * 80)
    logger.info(f"è°ƒè¯•å›¾åƒå¯¹æ•°: {max_debug}")
    logger.info(f"æˆåŠŸå¯¹é½: {success_count}")
    logger.info(f"æˆåŠŸç‡: {success_count/max_debug*100:.1f}%")
    logger.info(f"å¹³å‡åŒ¹é…ç‚¹æ•°: {total_matches/max_debug:.1f}")
    logger.info(f"å¹³å‡å†…ç‚¹æ•°: {total_inliers/max_debug:.1f}")
    logger.info(f"å¹³å‡å†…ç‚¹æ¯”ä¾‹: {total_inliers/total_matches*100 if total_matches > 0 else 0:.1f}%")
    
    # è¯Šæ–­å»ºè®®
    logger.info("\nğŸ”§ ä¼˜åŒ–å»ºè®®:")
    if success_count == 0:
        logger.info("- âŒ å®Œå…¨å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥å›¾åƒé¢„å¤„ç†å’Œæ¨¡å‹é…ç½®")
        logger.info("- ğŸ” å°è¯•é™ä½ç½®ä¿¡åº¦é˜ˆå€¼æˆ–è°ƒæ•´RANSACå‚æ•°")
    elif success_count < max_debug * 0.5:
        logger.info("- âš ï¸  æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–åŒ¹é…ç­–ç•¥")
        logger.info("- ğŸ”§ è€ƒè™‘ä½¿ç”¨å¤šå°ºåº¦åŒ¹é…æˆ–ç‰¹å¾èåˆ")
    else:
        logger.info("- âœ… æ•ˆæœå°šå¯ï¼Œå¯è¿›ä¸€æ­¥ä¼˜åŒ–å‚æ•°")

if __name__ == "__main__":
    main()